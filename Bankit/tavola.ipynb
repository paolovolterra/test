{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TAVOLE STATISTICHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3, pandas as pd, requests, os, sys, sqlalchemy, duckdb\n",
    "from io import BytesIO\n",
    "import json\n",
    "from pyjstat import pyjstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(\"D:/files/Bankit.sqlite\")\n",
    "from sqlalchemy import create_engine\n",
    "sqlite = create_engine('sqlite:///D:/files/Bankit.sqlite')\n",
    "\n",
    "def carica_dati_in_sql(tabella):\n",
    "    dtypes = {\n",
    "        \"DESINV\": sqlalchemy.types.INTEGER(),\n",
    "        \"DURORI\": sqlalchemy.types.INTEGER(),\n",
    "        \"TIPTASSO\": sqlalchemy.types.INTEGER(),\n",
    "        \"VALORE\": sqlalchemy.types.INTEGER(),\n",
    "        \"CLASSE_ACCORD\":sqlalchemy.types.TEXT()\n",
    "    }\n",
    "    data.to_sql(tabella, sqlite, if_exists='replace', index=False, dtype=dtypes)\n",
    "    return\n",
    "\n",
    "file_path = 'D:\\\\DatiStatistici.xlsx'\n",
    "# file_path = 'C:\\\\Users\\\\PVolterr\\\\Mediocredito Centrale S.p.A\\\\Studi e Governo Iniziative - Documenti\\\\dati statistici.xlsx'\n",
    "from openpyxl import load_workbook\n",
    "# os.chdir('C:\\\\Users\\\\PVolterr\\\\Mediocredito Centrale S.p.A\\\\Studi e Governo Iniziative - Documenti')\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "db_file = 'D:/files/Bankit.duckdb' # Nome del file del database\n",
    "ddb = duckdb.connect(db_file) # Connessione al database DuckDB (crea il file se non esiste)\n",
    "\n",
    "query = \"SELECT * FROM `domain-stacoris-multicube`\"\n",
    "stacoris = pd.read_sql_query(query, conn)\n",
    "query = \"SELECT * FROM `domain-stafinra-multicube`\"\n",
    "stafinra = pd.read_sql_query(query, conn)\n",
    "query = \"SELECT * FROM `domain-stamen-multicube`\"\n",
    "stamen = pd.read_sql_query(query, conn)\n",
    "\n",
    "nuts1 = ['IT','ITC','ITC1','ITC2','ITC3','ITC4','ITH','ITH3','ITH4','ITH5','ITHBI12','ITI','ITI1','ITI3','ITI4','ITF','ITF1','ITF2','ITF3','ITF4','ITF5','ITF6','ITG','ITG1','ITG2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TDB10255 - sostituito nel 2017 da TFR10255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ATECO_CTP</th>\n",
       "      <th>DATA_OSS</th>\n",
       "      <th>ENTE_SEGN</th>\n",
       "      <th>LOC_CTP</th>\n",
       "      <th>SET_CTP</th>\n",
       "      <th>VALORE</th>\n",
       "      <th>segnalante</th>\n",
       "      <th>area</th>\n",
       "      <th>target</th>\n",
       "      <th>ATECO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19795</th>\n",
       "      <td>1000063</td>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>1070001</td>\n",
       "      <td>ITF6</td>\n",
       "      <td>SBI25</td>\n",
       "      <td>25503</td>\n",
       "      <td>Banche e Cassa depositi e prestiti</td>\n",
       "      <td>Calabria</td>\n",
       "      <td>Società non finanziarie e famiglie produttrici</td>\n",
       "      <td>Carta, articoli di carta e prodotti della stampa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ATECO_CTP   DATA_OSS ENTE_SEGN LOC_CTP SET_CTP  VALORE  \\\n",
       "19795   1000063 2020-03-31   1070001    ITF6   SBI25   25503   \n",
       "\n",
       "                               segnalante      area  \\\n",
       "19795  Banche e Cassa depositi e prestiti  Calabria   \n",
       "\n",
       "                                               target  \\\n",
       "19795  Società non finanziarie e famiglie produttrici   \n",
       "\n",
       "                                                  ATECO  \n",
       "19795  Carta, articoli di carta e prodotti della stampa  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabella = 'TFR10255'\n",
    "file = f'https://a2a.bancaditalia.it/infostat/dataservices/export/IT/CSV/DATA/CUBE/BANKITALIA/DIFF/{tabella}'\n",
    "result = requests.get(file)\n",
    "date_column = ['DATA_OSS']\n",
    "data = pd.read_csv(BytesIO(result.content),compression='zip', header=0, sep=';', quotechar='\"', encoding='utf-8',dtype={'ENTE_SEGN':'str', 'FENEC':'str', 'VALORE':'Int32','LOC_SPORT':'Int32'},parse_dates=date_column, dayfirst=False)\n",
    "data['DATA_OSS'] = pd.to_datetime(data['DATA_OSS'])\n",
    "# data = data[data['DATA_OSS'] == data['DATA_OSS'].max()]\n",
    "# data['DATA_OSS'] = data['DATA_OSS'].dt.date\n",
    "# data = data[data['LOC_CTP'].isin(nuts1)]\n",
    "data = pd.merge(data, stafinra, how = 'left', left_on='ENTE_SEGN', right_on='Elemento').drop(columns=['STATUS','FENEC','Dominio','Elemento']).rename(columns={'Descrizione': 'segnalante'})\n",
    "data = pd.merge(data, stafinra, how = 'left', left_on='LOC_CTP', right_on='Elemento').drop(columns=['Dominio', 'Elemento']).rename(columns={'Descrizione': 'area'})\n",
    "data = pd.merge(data, stafinra, how = 'left', left_on='SET_CTP', right_on='Elemento').drop(columns=['Dominio', 'Elemento']).rename(columns={'Descrizione': 'target'})\n",
    "data = pd.merge(data, stafinra, how = 'left', left_on='ATECO_CTP', right_on='Elemento').drop(columns=['Dominio', 'Elemento']).rename(columns={'Descrizione': 'ATECO'})\n",
    "# data = data[['DATA_OSS', 'LOC_CTP', 'area', 'SET_CTP','target','VALORE']]\n",
    "data.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58625, 10)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "carica_dati_in_sql(tabella)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<duckdb.duckdb.DuckDBPyConnection at 0x1a6fae1d2f0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddb.execute(f\"DROP TABLE IF EXISTS {tabella}\")\n",
    "ddb.execute(f\"CREATE TABLE IF NOT EXISTS {tabella} AS SELECT * FROM data LIMIT 0\")  # Crea una tabella vuota con la struttura del DataFrame\n",
    "ddb.execute(f\"INSERT INTO {tabella} SELECT * FROM data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet_to_update = tabella\n",
    "book = load_workbook(file_path)\n",
    "with pd.ExcelWriter(file_path, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "    data.to_excel(writer, sheet_name=sheet_to_update, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TDB10266 DEPOSITS | Distribution by customer location (geographical area) and branch of economic activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATA_OSS</th>\n",
       "      <th>DIVISA1</th>\n",
       "      <th>DURORI</th>\n",
       "      <th>ENTE_SEGN</th>\n",
       "      <th>FENEC</th>\n",
       "      <th>LOC_CTP</th>\n",
       "      <th>RAMATECO</th>\n",
       "      <th>RESIDENZA1</th>\n",
       "      <th>SET_CTP</th>\n",
       "      <th>VALORE</th>\n",
       "      <th>STATUS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-09-30</td>\n",
       "      <td>1000</td>\n",
       "      <td>9</td>\n",
       "      <td>1100010</td>\n",
       "      <td>1041810</td>\n",
       "      <td>IT</td>\n",
       "      <td>51</td>\n",
       "      <td>IT</td>\n",
       "      <td>SBI25</td>\n",
       "      <td>8747852</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-09-30</td>\n",
       "      <td>1000</td>\n",
       "      <td>9</td>\n",
       "      <td>1100010</td>\n",
       "      <td>1041810</td>\n",
       "      <td>IT</td>\n",
       "      <td>52</td>\n",
       "      <td>IT</td>\n",
       "      <td>SBI25</td>\n",
       "      <td>8035032</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-09-30</td>\n",
       "      <td>1000</td>\n",
       "      <td>9</td>\n",
       "      <td>1100010</td>\n",
       "      <td>1041810</td>\n",
       "      <td>IT</td>\n",
       "      <td>53</td>\n",
       "      <td>IT</td>\n",
       "      <td>SBI25</td>\n",
       "      <td>2132191</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-09-30</td>\n",
       "      <td>1000</td>\n",
       "      <td>9</td>\n",
       "      <td>1100010</td>\n",
       "      <td>1041810</td>\n",
       "      <td>IT</td>\n",
       "      <td>54</td>\n",
       "      <td>IT</td>\n",
       "      <td>SBI25</td>\n",
       "      <td>2827730</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-09-30</td>\n",
       "      <td>1000</td>\n",
       "      <td>9</td>\n",
       "      <td>1100010</td>\n",
       "      <td>1041810</td>\n",
       "      <td>IT</td>\n",
       "      <td>55</td>\n",
       "      <td>IT</td>\n",
       "      <td>SBI25</td>\n",
       "      <td>3117736</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6187</th>\n",
       "      <td>1998-03-31</td>\n",
       "      <td>1000</td>\n",
       "      <td>9</td>\n",
       "      <td>1100010</td>\n",
       "      <td>1041810</td>\n",
       "      <td>ITI</td>\n",
       "      <td>70</td>\n",
       "      <td>IT</td>\n",
       "      <td>SBI25</td>\n",
       "      <td>118544</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6188</th>\n",
       "      <td>1998-03-31</td>\n",
       "      <td>1000</td>\n",
       "      <td>9</td>\n",
       "      <td>1100010</td>\n",
       "      <td>1041810</td>\n",
       "      <td>ITI</td>\n",
       "      <td>71</td>\n",
       "      <td>IT</td>\n",
       "      <td>SBI25</td>\n",
       "      <td>281756</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6189</th>\n",
       "      <td>1998-03-31</td>\n",
       "      <td>1000</td>\n",
       "      <td>9</td>\n",
       "      <td>1100010</td>\n",
       "      <td>1041810</td>\n",
       "      <td>ITI</td>\n",
       "      <td>72</td>\n",
       "      <td>IT</td>\n",
       "      <td>SBI25</td>\n",
       "      <td>83151</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6190</th>\n",
       "      <td>1998-03-31</td>\n",
       "      <td>1000</td>\n",
       "      <td>9</td>\n",
       "      <td>1100010</td>\n",
       "      <td>1041810</td>\n",
       "      <td>ITI</td>\n",
       "      <td>73</td>\n",
       "      <td>IT</td>\n",
       "      <td>SBI25</td>\n",
       "      <td>3836204</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6191</th>\n",
       "      <td>1998-03-31</td>\n",
       "      <td>1000</td>\n",
       "      <td>9</td>\n",
       "      <td>1100010</td>\n",
       "      <td>1041810</td>\n",
       "      <td>ITI</td>\n",
       "      <td>4999</td>\n",
       "      <td>IT</td>\n",
       "      <td>SBI25</td>\n",
       "      <td>16025914</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6192 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       DATA_OSS  DIVISA1  DURORI ENTE_SEGN    FENEC LOC_CTP  RAMATECO  \\\n",
       "0    2008-09-30     1000       9   1100010  1041810      IT        51   \n",
       "1    2008-09-30     1000       9   1100010  1041810      IT        52   \n",
       "2    2008-09-30     1000       9   1100010  1041810      IT        53   \n",
       "3    2008-09-30     1000       9   1100010  1041810      IT        54   \n",
       "4    2008-09-30     1000       9   1100010  1041810      IT        55   \n",
       "...         ...      ...     ...       ...      ...     ...       ...   \n",
       "6187 1998-03-31     1000       9   1100010  1041810     ITI        70   \n",
       "6188 1998-03-31     1000       9   1100010  1041810     ITI        71   \n",
       "6189 1998-03-31     1000       9   1100010  1041810     ITI        72   \n",
       "6190 1998-03-31     1000       9   1100010  1041810     ITI        73   \n",
       "6191 1998-03-31     1000       9   1100010  1041810     ITI      4999   \n",
       "\n",
       "     RESIDENZA1 SET_CTP    VALORE  STATUS  \n",
       "0            IT   SBI25   8747852     NaN  \n",
       "1            IT   SBI25   8035032     NaN  \n",
       "2            IT   SBI25   2132191     NaN  \n",
       "3            IT   SBI25   2827730     NaN  \n",
       "4            IT   SBI25   3117736     NaN  \n",
       "...         ...     ...       ...     ...  \n",
       "6187         IT   SBI25    118544     NaN  \n",
       "6188         IT   SBI25    281756     NaN  \n",
       "6189         IT   SBI25     83151     NaN  \n",
       "6190         IT   SBI25   3836204     NaN  \n",
       "6191         IT   SBI25  16025914     NaN  \n",
       "\n",
       "[6192 rows x 11 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabella = 'TDB10266'\n",
    "file = f'https://a2a.bancaditalia.it/infostat/dataservices/export/IT/CSV/DATA/CUBE/BANKITALIA/DIFF/{tabella}'\n",
    "result = requests.get(file)\n",
    "date_column = ['DATA_OSS']\n",
    "data = pd.read_csv(BytesIO(result.content),compression='zip', header=0, sep=';', quotechar='\"', encoding='utf-8',dtype={'ENTE_SEGN':'str', 'FENEC':'str', 'VALORE':'Int32','LOC_SPORT':'Int32'},parse_dates=date_column, dayfirst=False)\n",
    "data['DATA_OSS'] = pd.to_datetime(data['DATA_OSS'])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2008-09-30 00:00:00')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['DATA_OSS'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# data = data[data['DATA_OSS'] == data['DATA_OSS'].max()]\n",
    "# data['DATA_OSS'] = data['DATA_OSS'].dt.date\n",
    "# data = data[data['LOC_CTP'].isin(nuts1)]\n",
    "data = pd.merge(data, stamen, how = 'left', left_on='ENTE_SEGN', right_on='Elemento').drop(columns=['ENTE_SEGN','STATUS','FENEC','index','Dominio','Elemento']).rename(columns={'Descrizione': 'segnalante'})\n",
    "data = pd.merge(data, stamen, how = 'left', left_on='LOC_CTP', right_on='Elemento').drop(columns=['index','Dominio', 'Elemento']).rename(columns={'Descrizione': 'area'})\n",
    "data = pd.merge(data, stamen, how = 'left', left_on='SET_CTP', right_on='Elemento').drop(columns=['index','Dominio', 'Elemento']).rename(columns={'Descrizione': 'target'})\n",
    "# data = data[['DATA_OSS', 'LOC_CTP', 'area', 'SET_CTP','target','VALORE']]\n",
    "dtypes = {\"DIVISA1\": sqlalchemy.types.INTEGER(), \"DURORI\": sqlalchemy.types.INTEGER(),\"LOC_SPORT\": sqlalchemy.types.INTEGER(),\n",
    "         \"VALORE\": sqlalchemy.types.INTEGER()}\n",
    "data.to_sql('TDB10266', sqlite, if_exists='replace', dtype=dtypes,index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet_to_update = tabella\n",
    "book = load_workbook(file_path)\n",
    "with pd.ExcelWriter(file_path, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "    data.to_excel(writer, sheet_name=sheet_to_update, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TDB10290"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabella = 'TDB10290'\n",
    "file = f'https://a2a.bancaditalia.it/infostat/dataservices/export/IT/CSV/DATA/CUBE/BANKITALIA/DIFF/{tabella}'\n",
    "result = requests.get(file)\n",
    "date_column = ['DATA_OSS']\n",
    "data = pd.read_csv(BytesIO(result.content),compression='zip', header=0, sep=';', quotechar='\"', encoding='utf-8',dtype={'ENTE_SEGN':'str', 'FENEC':'str', 'VALORE':'Int32','LOC_SPORT':'Int32'},parse_dates=date_column, dayfirst=False)\n",
    "data['DATA_OSS'] = pd.to_datetime(data['DATA_OSS'])\n",
    "data = data[data['DATA_OSS'] == data['DATA_OSS'].max()]\n",
    "data['DATA_OSS'] = data['DATA_OSS'].dt.date\n",
    "data = data[data['LOC_CTP'].isin(nuts1)]\n",
    "data = pd.merge(data, stamen, how = 'left', left_on='ENTE_SEGN', right_on='Elemento').drop(columns=['ENTE_SEGN','STATUS','FENEC','index','Dominio','Elemento']).rename(columns={'Descrizione': 'segnalante'})\n",
    "data = pd.merge(data, stamen, how = 'left', left_on='LOC_CTP', right_on='Elemento').drop(columns=['index','Dominio', 'Elemento']).rename(columns={'Descrizione': 'area'})\n",
    "data = pd.merge(data, stamen, how = 'left', left_on='SET_CTP', right_on='Elemento').drop(columns=['index','Dominio', 'Elemento']).rename(columns={'Descrizione': 'target'})\n",
    "data = data[['DATA_OSS', 'LOC_CTP', 'area', 'SET_CTP','target','VALORE']]\n",
    "sheet_to_update = tabella\n",
    "book = load_workbook(file_path)\n",
    "with pd.ExcelWriter(file_path, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "    data.to_excel(writer, sheet_name=sheet_to_update, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabella = 'TDB10295'\n",
    "file = f'https://a2a.bancaditalia.it/infostat/dataservices/export/IT/CSV/DATA/CUBE/BANKITALIA/DIFF/{tabella}'\n",
    "result = requests.get(file)\n",
    "date_column = ['DATA_OSS']\n",
    "data = pd.read_csv(BytesIO(result.content),compression='zip', header=0, sep=';', quotechar='\"', encoding='utf-8',dtype={'ENTE_SEGN':'str', 'FENEC':'str', 'VALORE':'Int32','LOC_SPORT':'Int32'},parse_dates=date_column, dayfirst=False)\n",
    "data['DATA_OSS'] = pd.to_datetime(data['DATA_OSS'])\n",
    "data = data[data['DATA_OSS'] == data['DATA_OSS'].max()]\n",
    "data['DATA_OSS'] = data['DATA_OSS'].dt.date\n",
    "data = data[data['LOC_CTP'].isin(nuts1)]\n",
    "data = pd.merge(data, stamen, how = 'left', left_on='ENTE_SEGN', right_on='Elemento').drop(columns=['ENTE_SEGN','STATUS','FENEC','index','Dominio','Elemento']).rename(columns={'Descrizione': 'segnalante'})\n",
    "data = pd.merge(data, stamen, how = 'left', left_on='LOC_CTP', right_on='Elemento').drop(columns=['index','Dominio', 'Elemento']).rename(columns={'Descrizione': 'area'})\n",
    "data = pd.merge(data, stamen, how = 'left', left_on='SET_CTP', right_on='Elemento').drop(columns=['index','Dominio', 'Elemento']).rename(columns={'Descrizione': 'target'})\n",
    "data = data[['DATA_OSS', 'LOC_CTP', 'area', 'SET_CTP','target','VALORE']]\n",
    "sheet_to_update = tabella\n",
    "book = load_workbook(file_path)\n",
    "with pd.ExcelWriter(file_path, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "    data.to_excel(writer, sheet_name=sheet_to_update, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabella = 'TDB20290'\n",
    "file = f'https://a2a.bancaditalia.it/infostat/dataservices/export/IT/CSV/DATA/CUBE/BANKITALIA/DIFF/{tabella}'\n",
    "result = requests.get(file)\n",
    "date_column = ['DATA_OSS']\n",
    "data = pd.read_csv(BytesIO(result.content),compression='zip', header=0, sep=';', quotechar='\"', encoding='utf-8',dtype={'ENTE_SEGN':'str', 'FENEC':'str', 'VALORE':'Int32','LOC_SPORT':'Int32'},parse_dates=date_column, dayfirst=False)\n",
    "data['DATA_OSS'] = pd.to_datetime(data['DATA_OSS'])\n",
    "#data = data[data['DATA_OSS'] == data['DATA_OSS'].max()]\n",
    "data['DATA_OSS'] = data['DATA_OSS'].dt.date\n",
    "#data = data[data['LOC_CTP'].isin(nuts1)]\n",
    "data = pd.merge(data, stamen, how = 'left', left_on='ENTE_SEGN', right_on='Elemento').drop(columns=['ENTE_SEGN','STATUS','FENEC','index','Dominio','Elemento']).rename(columns={'Descrizione': 'segnalante'})\n",
    "data = pd.merge(data, stamen, how = 'left', left_on='LOC_CTP', right_on='Elemento').drop(columns=['index','Dominio', 'Elemento']).rename(columns={'Descrizione': 'area'})\n",
    "data = pd.merge(data, stamen, how = 'left', left_on='SET_CTP', right_on='Elemento').drop(columns=['index','Dominio', 'Elemento']).rename(columns={'Descrizione': 'target'})\n",
    "data = data[['DATA_OSS', 'LOC_CTP', 'area', 'SET_CTP','target','VALORE']]\n",
    "sheet_to_update = tabella\n",
    "book = load_workbook(file_path)\n",
    "with pd.ExcelWriter(file_path, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "    data.to_excel(writer, sheet_name=sheet_to_update, index=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "tabella = 'TFR10255'\n",
    "file = f'https://a2a.bancaditalia.it/infostat/dataservices/export/IT/CSV/DATA/CUBE/BANKITALIA/DIFF/{tabella}'\n",
    "result = requests.get(file)\n",
    "date_column = ['DATA_OSS']\n",
    "data = pd.read_csv(BytesIO(result.content),compression='zip', header=0, sep=';', quotechar='\"', encoding='utf-8',dtype={'ENTE_SEGN':'str', 'FENEC':'str', 'VALORE':'Int32','LOC_SPORT':'Int32'},parse_dates=date_column, dayfirst=False)\n",
    "data['DATA_OSS'] = pd.to_datetime(data['DATA_OSS'])\n",
    "data = data[data['DATA_OSS'] == data['DATA_OSS'].max()]\n",
    "data['DATA_OSS'] = data['DATA_OSS'].dt.date\n",
    "data = data[data['LOC_CTP'].isin(nuts1)]\n",
    "data = pd.merge(data, stamen, how = 'left', left_on='ENTE_SEGN', right_on='Elemento').drop(columns=['ENTE_SEGN','STATUS','FENEC','index','Dominio','Elemento']).rename(columns={'Descrizione': 'segnalante'})\n",
    "data = pd.merge(data, stamen, how = 'left', left_on='LOC_CTP', right_on='Elemento').drop(columns=['index','Dominio', 'Elemento']).rename(columns={'Descrizione': 'area'})\n",
    "data = pd.merge(data, stamen, how = 'left', left_on='SET_CTP', right_on='Elemento').drop(columns=['index','Dominio', 'Elemento']).rename(columns={'Descrizione': 'target'})\n",
    "data = pd.merge(data, stamen, how = 'left', left_on='ATECO_CTP', right_on='Elemento').drop(columns=['index','Dominio', 'Elemento']).rename(columns={'Descrizione': 'ATECO'})\n",
    "data = data[['DATA_OSS', 'LOC_CTP', 'area', 'ATECO_CTP', 'ATECO','SET_CTP','target','VALORE']]\n",
    "sheet_to_update = tabella\n",
    "book = load_workbook(file_path)\n",
    "with pd.ExcelWriter(file_path, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "    data.to_excel(writer, sheet_name=sheet_to_update, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabella = 'TFR20231'\n",
    "file = f'https://a2a.bancaditalia.it/infostat/dataservices/export/IT/CSV/DATA/CUBE/BANKITALIA/DIFF/{tabella}'\n",
    "result = requests.get(file)\n",
    "date_column = ['DATA_OSS']\n",
    "data = pd.read_csv(BytesIO(result.content),compression='zip', header=0, sep=';', quotechar='\"', decimal=',', encoding='utf-8',dtype={'ENTE_SEGN':'str', 'FENEC':'str', 'VALORE':'float64','LOC_SPORT':'Int32'},parse_dates=date_column, dayfirst=False)\n",
    "data['DATA_OSS'] = pd.to_datetime(data['DATA_OSS'])\n",
    "data = data[data['DATA_OSS'] == data['DATA_OSS'].max()]\n",
    "data['DATA_OSS'] = data['DATA_OSS'].dt.date\n",
    "data = data[data['LOC_CTP'].isin(nuts1)]\n",
    "data = pd.merge(data, stamen, how = 'left', left_on='ENTE_SEGN', right_on='Elemento').drop(columns=['ENTE_SEGN','STATUS','FENEC','index','Dominio','Elemento']).rename(columns={'Descrizione': 'segnalante'})\n",
    "data = pd.merge(data, stamen, how = 'left', left_on='LOC_CTP', right_on='Elemento').drop(columns=['index','Dominio', 'Elemento']).rename(columns={'Descrizione': 'area'})\n",
    "data = pd.merge(data, stamen, how = 'left', left_on='SET_CTP', right_on='Elemento').drop(columns=['index','Dominio', 'Elemento']).rename(columns={'Descrizione': 'target'})\n",
    "#data = pd.merge(data, stamen, how = 'left', left_on='ATECO_CTP', right_on='Elemento').drop(columns=['index','Dominio', 'Elemento']).rename(columns={'Descrizione': 'ATECO'})\n",
    "data = data[['DATA_OSS', 'LOC_CTP', 'area', 'SET_CTP','target','VALORE']] # 'ATECO_CTP', 'ATECO',\n",
    "sheet_to_update = tabella\n",
    "book = load_workbook(file_path)\n",
    "with pd.ExcelWriter(file_path, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "    data.to_excel(writer, sheet_name=sheet_to_update, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabella = 'TRI30603'\n",
    "file = f'https://a2a.bancaditalia.it/infostat/dataservices/export/IT/CSV/DATA/CUBE/BANKITALIA/DIFF/{tabella}'\n",
    "result = requests.get(file)\n",
    "date_column = ['DATA_OSS']\n",
    "data = pd.read_csv(BytesIO(result.content),compression='zip', header=0, sep=';', quotechar='\"', decimal=',', encoding='utf-8',dtype={'ENTE_SEGN':'str', 'FENEC':'str', 'VALORE':'float64','LOC_SPORT':'Int32'},parse_dates=date_column, dayfirst=False)\n",
    "data['DATA_OSS'] = pd.to_datetime(data['DATA_OSS'])\n",
    "data = data[data['DATA_OSS'] == data['DATA_OSS'].max()]\n",
    "data['DATA_OSS'] = data['DATA_OSS'].dt.date\n",
    "data = data[data['SEDELEG_SOGG'].isin(nuts1)]\n",
    "data = pd.merge(data, stamen, how = 'left', left_on='ENTE_SEGN', right_on='Elemento').drop(columns=['ENTE_SEGN','STATUS','FENEC','index','Dominio','Elemento']).rename(columns={'Descrizione': 'segnalante'})\n",
    "data = pd.merge(data, stamen, how = 'left', left_on='SEDELEG_SOGG', right_on='Elemento').drop(columns=['index','Dominio', 'Elemento']).rename(columns={'Descrizione': 'area'})\n",
    "data = pd.merge(data, stamen, how = 'left', left_on='SET_CTP', right_on='Elemento').drop(columns=['index','Dominio', 'Elemento']).rename(columns={'Descrizione': 'target'})\n",
    "#data = pd.merge(data, stamen, how = 'left', left_on='ATECO_CTP', right_on='Elemento').drop(columns=['index','Dominio', 'Elemento']).rename(columns={'Descrizione': 'ATECO'})\n",
    "data = data[['DATA_OSS', 'SEDELEG_SOGG', 'area', 'SET_CTP','target','VALORE']] # 'ATECO_CTP', 'ATECO',\n",
    "sheet_to_update = tabella\n",
    "book = load_workbook(file_path)\n",
    "with pd.ExcelWriter(file_path, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "    data.to_excel(writer, sheet_name=sheet_to_update, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRI30146 Prestiti (escluse sofferenze) - per regione della clientela e classe di grandezza del fido globale accordato \n",
    "tabella = 'TRI30146'\n",
    "file = f'https://a2a.bancaditalia.it/infostat/dataservices/export/IT/CSV/DATA/CUBE/BANKITALIA/DIFF/{tabella}'\n",
    "result = requests.get(file)\n",
    "date_column = ['DATA_OSS']\n",
    "data = pd.read_csv(BytesIO(result.content),compression='zip', header=0, sep=';', quotechar='\"', decimal=',', encoding='utf-8',dtype={'ENTE_SEGN':'str', 'FENEC':'str', 'VALORE':'float64','LOC_SPORT':'Int32'},parse_dates=date_column, dayfirst=False)\n",
    "data['DATA_OSS'] = pd.to_datetime(data['DATA_OSS'])\n",
    "data = data[data['DATA_OSS'] == data['DATA_OSS'].max()]\n",
    "data['DATA_OSS'] = data['DATA_OSS'].dt.date\n",
    "data = data[data['SEDELEG_SOGG'].isin(nuts1)]\n",
    "sheet_to_update = tabella\n",
    "book = load_workbook(file_path)\n",
    "with pd.ExcelWriter(file_path, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "    data.to_excel(writer, sheet_name=sheet_to_update, index=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "\n",
    "query = \"SELECT b.descrizione classe, c.Descrizione FenEc, SEDELEG_SOGG, d.Descrizione AREA, VALORE from TRI30146 a \\\n",
    "left join `domain-stacoris-multicube` b on a.CLASSE_ACCORD = b.Elemento \\\n",
    "left join `domain-stacoris-multicube` c on a.FENEC = c.Elemento \\\n",
    "left join `domain-stacoris-multicube` d on a.SEDELEG_SOGG = d.Elemento \\\n",
    "where DATA_OSS = '2018-12-31 00:00:00.000000' and ENTE_SEGN = '1100010';\"\n",
    "df = pd.read_sql_query(query, conn)\n",
    "df['FenEc'] = df['FenEc'].str.replace('Prestiti (escluse sofferenze): ','')\n",
    "nuts = ['IT','ITC','ITC1','ITC2','ITC3','ITC4','ITH','ITH3','ITH4','ITH5','ITHBI12','ITI','ITI1','ITI3','ITI4','ITF','ITF1','ITF2','ITF3','ITF4','ITF5','ITF6','ITG','ITG1','ITG2']\n",
    "df = df[df['SEDELEG_SOGG'].isin(nuts)]\n",
    "\n",
    "df_grouped = df.groupby(['FenEc','AREA','classe'])['VALORE'].sum().reset_index()\n",
    "custom_order = [\"accordato operativo\", \"utilizzato\", \"numero di affidati\"]\n",
    "df_grouped[\"FenEc\"] = pd.Categorical(df_grouped[\"FenEc\"], categories=custom_order, ordered=True)\n",
    "df_grouped = df_grouped.sort_values(by=\"FenEc\")\n",
    "# df_grouped.to_excel(\"D:/dati statistici.xlsx\", sheet_name=\"TRI30146\", index=False)\n",
    "'''\n",
    "df_pivot = df.pivot_table(index=['FenEc', 'AREA'], columns='classe', values='VALORE', aggfunc='sum')\n",
    "# Resettare l'indice per poter riordinare 'FenEc'\n",
    "df_pivot = df_pivot.reset_index()\n",
    "# Applicare l'ordine personalizzato a 'FenEc'\n",
    "custom_order = [\"accordato operativo\", \"utilizzato\", \"numero di affidati\"]\n",
    "df_pivot[\"FenEc\"] = pd.Categorical(df_pivot[\"FenEc\"], categories=custom_order, ordered=True)\n",
    "# Ordinare in base a 'FenEc'\n",
    "df_pivot.sort_values(by=\"FenEc\")\n",
    "# df_pivot.to_excel(\"D:/dati statistici.xlsx\", sheet_name=\"TRI30146\", index=False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Istat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'writer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m df1 \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mquery(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVALUATION == \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mV\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m and TIME_PERIOD == \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2022\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m and DATA_TYPE_AGGR in [\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mB1G_B_W2_S1_R_POP\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mB1GQ_B_W2_S1_R_POP\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mB1G_B_W2_S1\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     19\u001b[0m )\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mB1GQ_B_W2_S1_R_POP\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPIL/abitante\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mB1G_B_W2_S1_R_POP\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVal.Aggiunto/abitante\u001b[39m\u001b[38;5;124m\"\u001b[39m)[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEDITION\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTIME_PERIOD\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mREF_AREA\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDATA_TYPE_AGGR\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOBS_VALUE\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m     20\u001b[0m ValProCapite \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mpivot_table(df1, index \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mREF_AREA\u001b[39m\u001b[38;5;124m'\u001b[39m, columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDATA_TYPE_AGGR\u001b[39m\u001b[38;5;124m'\u001b[39m, values \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOBS_VALUE\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 21\u001b[0m ValProCapite\u001b[38;5;241m.\u001b[39mto_excel(\u001b[43mwriter\u001b[49m, sheet_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValProCapite\u001b[39m\u001b[38;5;124m'\u001b[39m, startrow\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, startcol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m#writer.close()\u001b[39;00m\n\u001b[0;32m     23\u001b[0m sheet_to_update \u001b[38;5;241m=\u001b[39m tabella\n",
      "\u001b[1;31mNameError\u001b[0m: name 'writer' is not defined"
     ]
    }
   ],
   "source": [
    "# Valori pro capite\n",
    "dataset = '93_1227_DF_DCCN_TNA1_6'\n",
    "data_url = f'https://esploradati.istat.it/SDMXWS/rest/data/IT1,{dataset},1.0/A........./ALL/?detail=full&startPeriod=2014-01-01&endPeriod=2023-12-31&dimensionAtObservation=TIME_PERIOD'\n",
    "response = requests.get(data_url)\n",
    "root = ET.fromstring(response.content)\n",
    "# 🔎 Namespace XML per SDMX aggiornato\n",
    "ns = {\"message\": \"http://www.sdmx.org/resources/sdmxml/schemas/v2_1/message\",\"generic\": \"http://www.sdmx.org/resources/sdmxml/schemas/v2_1/data/generic\"}\n",
    "data = []\n",
    "for series in root.findall(\".//generic:Series\", namespaces=ns):\n",
    "    series_key = series.find(\"generic:SeriesKey\", namespaces=ns)\n",
    "    attributes = {value.attrib[\"id\"]: value.attrib[\"value\"] for value in series_key.findall(\"generic:Value\", namespaces=ns)}\n",
    "    for obs in series.findall(\"generic:Obs\", namespaces=ns):\n",
    "        time_period = obs.find(\"generic:ObsDimension\", namespaces=ns).attrib[\"value\"]\n",
    "        obs_value = obs.find(\"generic:ObsValue\", namespaces=ns).attrib[\"value\"]\n",
    "        data.append({**attributes, \"TIME_PERIOD\": time_period, \"OBS_VALUE\": float(obs_value)})\n",
    "df = pd.DataFrame(data)\n",
    "# Valori pro capite\n",
    "df1 = df.query('VALUATION == \"V\" and TIME_PERIOD == \"2022\" and DATA_TYPE_AGGR in [\"B1G_B_W2_S1_R_POP\",\"B1GQ_B_W2_S1_R_POP\",\"B1G_B_W2_S1\"]'\n",
    ").replace(\"B1GQ_B_W2_S1_R_POP\", \"PIL/abitante\").replace(\"B1G_B_W2_S1_R_POP\", \"Val.Aggiunto/abitante\")[['EDITION','TIME_PERIOD', 'REF_AREA', 'DATA_TYPE_AGGR', 'OBS_VALUE']]\n",
    "ValProCapite = pd.pivot_table(df1, index = 'REF_AREA', columns='DATA_TYPE_AGGR', values = 'OBS_VALUE')\n",
    "ValProCapite.to_excel(writer, sheet_name='ValProCapite', startrow=3, startcol=2)\n",
    "\n",
    "sheet_to_update = tabella\n",
    "book = load_workbook(file_path)\n",
    "with pd.ExcelWriter(file_path, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "    df.to_excel(writer, sheet_name=sheet_to_update, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CCIAA Macerata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PVolterr\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyjstat\\pyjstat.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  dim_index = pd.DataFrame(list(zip([dim_label['id'][0]], [0])),\n"
     ]
    }
   ],
   "source": [
    "url = \"https://opendata.marche.camcom.it/data/Stock-Imprese-Attive-Italia-Natura-Giuridica.json\"\n",
    "response = requests.get(url)\n",
    "json_stat_data = response.json()\n",
    "dataset = pyjstat.Dataset(json_stat_data)\n",
    "df = dataset.write('dataframe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet_to_update = 'NatGiur'\n",
    "book = load_workbook(file_path)\n",
    "with pd.ExcelWriter(file_path, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "    df.to_excel(writer, sheet_name=sheet_to_update, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "# Connessione SQLite\n",
    "conn = sqlite3.connect(\"D:/files/Bankit.sqlite\")\n",
    "\n",
    "# Lista delle tabelle da elaborare\n",
    "tabelle = [\n",
    "    'TDB10224', 'TDB10226', 'TDB10290', 'TDB10295', 'TFR10255', 'TFR20231', 'TRI30603', 'TRI30146'\n",
    "]\n",
    "\n",
    "# Caricamento dei dati di riferimento\n",
    "stacoris = pd.read_sql_query(\"SELECT * FROM `domain-stacoris-multicube`\", conn)\n",
    "stafinra = pd.read_sql_query(\"SELECT * FROM `domain-stafinra-multicube`\", conn)\n",
    "stamen = pd.read_sql_query(\"SELECT * FROM `domain-stamen-multicube`\", conn)\n",
    "\n",
    "# Chiudere la connessione al database\n",
    "conn.close()\n",
    "\n",
    "# Definizione NUTS1\n",
    "nuts1 = ['IT', 'ITC', 'ITC1', 'ITC2', 'ITC3', 'ITC4', 'ITH', 'ITH3', 'ITH4', 'ITH5', 'ITHBI12', 'ITI', 'ITI1', 'ITI3', 'ITI4', 'ITF', 'ITF1', 'ITF2', 'ITF3', 'ITF4', 'ITF5', 'ITF6', 'ITG', 'ITG1', 'ITG2']\n",
    "\n",
    "# Percorso file di output\n",
    "file_path = 'D:/butta.xlsx'\n",
    "\n",
    "# Funzione per elaborare e salvare ogni tabella\n",
    "def process_table(tabella):\n",
    "    print(f\"Elaborazione tabella: {tabella}\")\n",
    "    url = f'https://a2a.bancaditalia.it/infostat/dataservices/export/IT/CSV/DATA/CUBE/BANKITALIA/DIFF/{tabella}'\n",
    "    result = requests.get(url)\n",
    "    \n",
    "    data = pd.read_csv(BytesIO(result.content), compression='zip', header=0, sep=';', quotechar='\"',\n",
    "                        encoding='utf-8', dtype={'ENTE_SEGN': 'str', 'FENEC': 'str', 'VALORE': 'float64', 'LOC_SPORT': 'Int32'},\n",
    "                        parse_dates=['DATA_OSS'], dayfirst=False)\n",
    "    \n",
    "    # Filtro sull'ultima data\n",
    "    data['DATA_OSS'] = pd.to_datetime(data['DATA_OSS']).dt.date\n",
    "    data = data[data['DATA_OSS'] == data['DATA_OSS'].max()]\n",
    "    \n",
    "    # Filtro sui codici NUTS1\n",
    "    if 'LOC_CTP' in data.columns:\n",
    "        data = data[data['LOC_CTP'].isin(nuts1)]\n",
    "    elif 'SEDELEG_SOGG' in data.columns:\n",
    "        data = data[data['SEDELEG_SOGG'].isin(nuts1)]\n",
    "    \n",
    "    # Merge con stamen per ottenere descrizioni\n",
    "    colonne_merge = ['ENTE_SEGN', 'LOC_CTP', 'SET_CTP', 'ATECO_CTP']\n",
    "    for col in colonne_merge:\n",
    "        if col in data.columns:\n",
    "            data = data.merge(stamen, how='left', left_on=col, right_on='Elemento').drop(columns=['index', 'Dominio', 'Elemento']).rename(columns={'Descrizione': col.lower()})\n",
    "    \n",
    "    # Selezione colonne finali\n",
    "    colonne_finali = [col for col in ['DATA_OSS', 'LOC_CTP', 'segnalante', 'area', 'ATECO_CTP', 'ATECO', 'SET_CTP', 'target', 'VALORE'] if col in data.columns]\n",
    "    data = data[colonne_finali]\n",
    "    \n",
    "    # Salvataggio su Excel\n",
    "    book = load_workbook(file_path)\n",
    "    with pd.ExcelWriter(file_path, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "        data.to_excel(writer, sheet_name=tabella, index=False)\n",
    "    print(f\"Tabella {tabella} elaborata e salvata con successo.\")\n",
    "\n",
    "# Elaborazione di tutte le tabelle\n",
    "for tabella in tabelle:\n",
    "    process_table(tabella)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
